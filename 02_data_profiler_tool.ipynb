{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2243815b-9bc0-4d03-b157-3806e6b9b194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS dq_table_metrics(\n",
    "              table_name STRING,\n",
    "              run_date DATE,\n",
    "              row_count LONG,\n",
    "              null_stats MAP<STRING, LONG>,\n",
    "              distinct_stats MAP<STRING, LONG>,\n",
    "              schema_hash STRING,\n",
    "              active_columns ARRAY<STRING>,\n",
    "              collected_ts TIMESTAMP\n",
    "          )\n",
    "          USING DELTA\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2bd9c2b-5db5-4178-a681-3ff2f68f4af5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def profile_table(table_name, run_date):\n",
    "    df = spark.table(table_name).filter(F.col(\"order_date\") == run_date)\n",
    "\n",
    "    row_count = df.count()\n",
    "\n",
    "    null_stats = {\n",
    "        c: df.filter(F.col(c).isNull()).count()\n",
    "        for c in df.columns\n",
    "    }\n",
    "\n",
    "    distinct_stats = {\n",
    "        c: df.select(c).distinct().count()\n",
    "        for c in df.columns\n",
    "    }\n",
    "\n",
    "    schema_string = \"|\".join(\n",
    "        [f\"{f.name}:{f.dataType.simpleString()}\" for f in df.schema.fields]\n",
    "    )\n",
    "\n",
    "    schema_hash = hashlib.md5(schema_string.encode()).hexdigest()\n",
    "\n",
    "    active_columns = [\n",
    "        c for c in df.columns\n",
    "        if df.filter(F.col(c).isNotNull()).limit(1).count() > 0\n",
    "    ]\n",
    "\n",
    "    metrics_df = spark.createDataFrame([(\n",
    "        table_name,\n",
    "        run_date,\n",
    "        row_count,\n",
    "        null_stats,\n",
    "        distinct_stats,\n",
    "        schema_hash,\n",
    "        active_columns\n",
    "    )],[\n",
    "        \"table_name\",\n",
    "        \"run_date\",\n",
    "        \"row_count\",\n",
    "        \"null_stats\",\n",
    "        \"distinct_stats\",\n",
    "        \"schema_hash\",\n",
    "        \"active_columns\"\n",
    "    ]).withColumn(\"collected_ts\", F.current_timestamp())\n",
    "\n",
    "    metrics_df.write.mode(\"append\").saveAsTable(\"dq_table_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e0c4a85-41d4-4849-88ae-7afc3e9414fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "#           ALTER TABLE dq_table_metrics ADD COLUMN (\n",
    "#               active_columns ARRAY<STRING>\n",
    "#           )\n",
    "#           \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e617fea-5cd6-4160-9e6a-db8d5d81fc1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dates = [\n",
    "    r.order_date for r in \n",
    "    spark.sql(\"SELECT DISTINCT order_date FROM retail_orders\").collect()\n",
    "]\n",
    "\n",
    "for d in dates:\n",
    "    profile_table(\"retail_orders\", d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "478ded2c-c4a6-418d-b14b-3fd5351fe95a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x  = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            run_date,\n",
    "            row_count,\n",
    "            null_stats[\"customer_id\"],\n",
    "            distinct_stats[\"product_id\"] as product_cardinality,\n",
    "            -- schemahash,\n",
    "            active_columns\n",
    "        FROM\n",
    "            dq_table_metrics \n",
    "        ORDER BY\n",
    "            run_date\"\"\")\n",
    "        #   \"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a47b100-3fa8-48d6-b918-9e1e4d659c04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4a2ee76-884e-404f-a30d-1158dcba51fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_data_profiler_tool",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
